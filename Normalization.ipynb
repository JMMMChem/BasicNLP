{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Normalization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4Gm0kEk15uOd","colab_type":"text"},"source":["# Normalization\n","\n","Variabilidad del lenguaje. Ejemplo: \n","\n","- Lisa **comió** la comida y lavó los platos.\n","- Estaban **comiendo** fideos en un café.\n","- ¿No quieres **comer** antes de que nos vayamos?\n","- **Comeré** el sábado con mis amigos.\n","- También **come** frutas y verduras.\n","\n","En el desarrollo de muchos sistemas de PLN, es necesario normalizar las palabras (convertirlas a su raíz o a su forma canónica) para evitar su posible variabilidad (distintas formas, pero igual significado semántico). \n","\n","\n","La normalización no sólo permite tratar la variabilidad, sino también disminuir el tamaño del dataset. \n","\n","Dos tipos de normalización:\n","- steming, que consiste transformar la palabra a su raíz.\n","- lematización, que es transformar una palabra a su lema o forma canónica. \n","\n","Stemming suele ser un proceso sencillo y rápido, basado en un conjunto de reglas que permite cortar la palabra a partir de un conjunto de prefijos y sufijos (por ejemplo, “ing”, “ly”, “es”, “s”).\n","\n","La lematización es más lento pero la información que devuelve es de mayor calidad ya que utiliza diccionarios con detallado conocimiento lingüístico. \n","\n","## Stemming con NLTK"]},{"cell_type":"code","metadata":{"id":"cF2QXtCK8t0K","colab_type":"code","outputId":"f1f0228f-a52f-4fd1-f578-b55f2b4d1470","executionInfo":{"status":"ok","timestamp":1574443370947,"user_tz":-60,"elapsed":539,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDzs7uESRgGXezTbdKoLEUmWmr1XiAmOPCTlj9n=s64","userId":"10362143810849156637"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["import nltk\n","#nltk.download('punkt')\n","#nltk.download('stopwords')\n","\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize \n","from nltk.stem import PorterStemmer\n","\n","set(stopwords.words('english'))\n","\n","text='The children were playing, while their parents were chatting.'\n","text=text.lower()\n","\n","stop_words = set(stopwords.words('english')) \n","  \n","word_tokens = word_tokenize(text) \n","    \n","filtered_sentence = [] \n","  \n","for w in word_tokens: \n","    if w not in stop_words: \n","        filtered_sentence.append(w) \n","\n","Stem_words = []\n","ps =PorterStemmer()\n","for w in filtered_sentence:\n","    rootWord=ps.stem(w)\n","    Stem_words.append(rootWord)\n","print(filtered_sentence)\n","print(Stem_words)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['children', 'playing', ',', 'parents', 'chatting', '.']\n","['children', 'play', ',', 'parent', 'chat', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hDqwtfsmJUC-","colab_type":"text"},"source":["## Lematización con NLKT"]},{"cell_type":"code","metadata":{"id":"JnB87vqDJX7c","colab_type":"code","outputId":"3a6b38bb-e121-4550-d27a-c34de3b719a6","executionInfo":{"status":"ok","timestamp":1574443572411,"user_tz":-60,"elapsed":2814,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDzs7uESRgGXezTbdKoLEUmWmr1XiAmOPCTlj9n=s64","userId":"10362143810849156637"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"source":["import nltk\n","\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize \n","\n","from nltk.stem import WordNetLemmatizer\n","set(stopwords.words('english'))\n","\n","text='The children were playing, while their parents were chatting.'\n","text=text.lower()\n","stop_words = set(stopwords.words('english')) \n","  \n","word_tokens = word_tokenize(text) \n","    \n","filtered_sentence = [] \n","  \n","for w in word_tokens: \n","    if w not in stop_words: \n","        filtered_sentence.append(w) \n","print(filtered_sentence) \n","\n","lemma_word = []\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","for w in filtered_sentence:\n","    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n","    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n","    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n","    lemma_word.append(word3)\n","print(lemma_word)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","['children', 'playing', ',', 'parents', 'chatting', '.']\n","['child', 'play', ',', 'parent', 'chat', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1Ql-v9QrCpd7","colab_type":"text"},"source":["## Lematización con Spacy\n","\n"]},{"cell_type":"code","metadata":{"id":"zzGHXwOUCsg_","colab_type":"code","outputId":"0db033d1-bf97-4aaf-ba20-1f99fe397db7","executionInfo":{"status":"ok","timestamp":1574443755192,"user_tz":-60,"elapsed":750,"user":{"displayName":"ISABEL SEGURA BEDMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDzs7uESRgGXezTbdKoLEUmWmr1XiAmOPCTlj9n=s64","userId":"10362143810849156637"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#make sure to download the english model with \"python -m spacy download en\"\n","\n","import en_core_web_sm\n","nlp = en_core_web_sm.load()\n","text='The children were playing, while their parents were chatting.'\n","text=text.lower()\n","doc = nlp(text)\n","\n","lemmas = [] \n","tokens=[]\n","for token in doc:\n","    lemmas.append(token.lemma_)\n","    tokens.append(token)\n","print(tokens)\n","print(lemmas)\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[the, children, were, playing, ,, while, their, parents, were, chatting, .]\n","['the', 'child', 'be', 'play', ',', 'while', '-PRON-', 'parent', 'be', 'chat', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TkUocQIdDRp9","colab_type":"text"},"source":["Existen otras librerías, como TextBlob, que también permiten realizar la lematización de un texto. \n"]}]}