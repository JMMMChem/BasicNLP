{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LabCase-ComplexWordIdentification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/TextSimplification/blob/master/LabCase_ComplexWordIdentification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mDPS6_LdxTN",
        "colab_type": "text"
      },
      "source": [
        "# Lab Case: Extending our CWI system.\n",
        "\n",
        "\n",
        "Our goal is to extend our CWI system by adding new features to represent each word. At leat, you should information about window features, that is, information about the two previous and next tokens of the word to be classified. We have already provided you several language models that you can use to obtain the probability of bigrams and trigrams, even 5-grams.\n",
        "\n",
        "You could also compare different classifiers. \n",
        "\n",
        "You could also consider the use of word embeddings as additional features, obtained by Spacy or by using Gensim. \n",
        "\n",
        "In the previous notebook, we used a subset of the original CWI dataset (https://sites.google.com/view/cwisharedtask2018/datasets?authuser=0). Our subset only contained English sentences.\n",
        "\n",
        "In this lab case, you could also consider to develop a CWI for Spanish or for German. Even, you could consider to develop a multilingual CWI system (Spanish, English and German). \n",
        "\n",
        "Another possible challenge that you could address is that the classification of multitokens as complex or simple words. In our subset, we removed the multitokens from the original dataset. So, you could work on the original dataset and  deal with the classification of the multitoken words. \n",
        "\n",
        "\n",
        "Please, **consider this as your final work** for this part of the course. \n",
        "**The more things you try to explore (features, classifiers, multitokens, different language, etc), the more grade you will get**. \n",
        "\n",
        "In addition to the notebook, you should write a paper describing the feature set, the architecture of your system and the results. The paper should include a discussion of the results, comparing the different features and algorithms used. \n",
        "\n"
      ]
    }
  ]
}