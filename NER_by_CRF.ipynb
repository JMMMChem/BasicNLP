{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER by CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isegura/BasicNLP/blob/master/NER_by_CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LGVaDj6PupB",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning based approach for NER (using Conditional Random Field (CRF)).\n",
        "\n",
        "\n",
        "https://www.aitimejournal.com/@akshay.chavan/complete-tutorial-on-named-entity-recognition-ner-using-python-and-keras\n",
        "\n",
        "\n",
        "In NLP, NER is a method of extracting the relevant information from a large corpus and classifying those entities into predefined categories such as location, organization, name and so on. This is a simple example and one can come up with complex entity recognition related to domain-specific with the problem at hand.\n",
        "\n",
        "<img src='https://d2ueix13hy5h3i.cloudfront.net/wp-content/uploads/2019/06/3.png' width=800>\n",
        "\n",
        "In this tutorial, we will use the following dataset\n",
        "\n",
        "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus#ner_dataset.csv\n",
        "\n",
        "This dataset is extracted from GMB(Groningen Meaning Bank) corpus which is tagged, annotated and built specifically to train the classifier to predict named entities such as name, location, etc.\n",
        "All the entities are labeled using the BIO scheme, where each entity label is prefixed with either B or I letter. B- denotes the beginning and I- inside of an entity. The words which are not of interest are labeled with 0 – tag.\n",
        "\n",
        "<img src='https://d2ueix13hy5h3i.cloudfront.net/wp-content/uploads/2019/06/Capture1.png' width=350>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_1v6O2zTGK_",
        "colab_type": "text"
      },
      "source": [
        "Before to load the dataset, we need to mount our folder in google drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05N_SwgGTL6t",
        "colab_type": "code",
        "outputId": "a6bacbbb-f247-4990-bfdf-8bcc25839861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount(\"/content/drive/\")\n",
        "\n",
        "path='drive/My Drive/Colab Notebooks/TESI/4-NER/'\n",
        "!ls 'drive/My Drive/Colab Notebooks/TESI/4-NER/'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " chemdner_corpus\t\t       IntroNER-spacy.ipynb   Untitled0.ipynb\n",
            " data\t\t\t\t      'NER by CRF.ipynb'\n",
            "'Dictionary based NER (spacy).ipynb'   resources\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scn6jrRSUoKx",
        "colab_type": "text"
      },
      "source": [
        "First, we must load the libraries that we will use in this notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtRt1ONNabh8",
        "colab_type": "code",
        "outputId": "a1a28211-a3a6-4517-dac5-2b3fe9708eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install sklearn-crfsuite\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn_crfsuite import CRF\n",
        "from sklearn_crfsuite.metrics import flat_f1_score\n",
        "from sklearn_crfsuite.metrics import flat_classification_report"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (0.8.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite) (4.28.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq4pH_wOU1lz",
        "colab_type": "text"
      },
      "source": [
        "Now, we can load the dataset. Sentence # indicates the sentence number and each sentence comprises of words that are labeled using the BIO scheme in the tag column.\n",
        "\n",
        "This particular dataset has 47959 sentences and 35178 unique words. \n",
        "\n",
        "Observations :\n",
        "- There are total 47959 sentences in the dataset.\n",
        "- Number unique words in the dataset are 35178.\n",
        "- Total 17 lables (Tags).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYF3qJjxTsH6",
        "colab_type": "code",
        "outputId": "d226f893-c406-4475-a02b-650cf53be337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "import pandas as pd\n",
        "path_data=path+'data/ner_dataset.csv'\n",
        "\n",
        "#Reading the csv file\n",
        "df = pd.read_csv(path_data, encoding = \"ISO-8859-1\")\n",
        "print(df.head(15))\n",
        "print()\n",
        "print('some statistics about the dataset:')\n",
        "df.describe()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Sentence #           Word  POS    Tag\n",
            "0   Sentence: 1      Thousands  NNS      O\n",
            "1           NaN             of   IN      O\n",
            "2           NaN  demonstrators  NNS      O\n",
            "3           NaN           have  VBP      O\n",
            "4           NaN        marched  VBN      O\n",
            "5           NaN        through   IN      O\n",
            "6           NaN         London  NNP  B-geo\n",
            "7           NaN             to   TO      O\n",
            "8           NaN        protest   VB      O\n",
            "9           NaN            the   DT      O\n",
            "10          NaN            war   NN      O\n",
            "11          NaN             in   IN      O\n",
            "12          NaN           Iraq  NNP  B-geo\n",
            "13          NaN            and   CC      O\n",
            "14          NaN         demand   VB      O\n",
            "\n",
            "some statistics about the dataset:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47959</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 534</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Sentence #     Word      POS      Tag\n",
              "count           47959  1048575  1048575  1048575\n",
              "unique          47959    35178       42       17\n",
              "top     Sentence: 534      the       NN        O\n",
              "freq                1    52573   145807   887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKUZVyNLVn2q",
        "colab_type": "text"
      },
      "source": [
        "Let us to show the set of tags, which are the classes to classify the tokens based on the IOB schema:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUsyyVOGVz6a",
        "colab_type": "code",
        "outputId": "5c8e37c1-d0f9-447a-ef9f-59f4b610316f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "##Displaying the unique Tags\n",
        "df['Tag'].unique()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1zGQUhKbCyO",
        "colab_type": "code",
        "outputId": "ff07d4ee-6951-4e7f-a332-14e5ce6e4515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "#Checking null values, if any.\n",
        "df.isnull().sum()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omW6xm1_bKSR",
        "colab_type": "text"
      },
      "source": [
        "There are lots of missing values in 'Sentence #' attribute. So we will use pandas fillna technique and use 'ffill' method which propagates last valid observation forward to next.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoEZ2PaubICR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a2f54207-58ed-49e3-ac94-9f4763a4a4e8"
      },
      "source": [
        "df = df.fillna(method = 'ffill')\n",
        "df.head(100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>ruling</td>\n",
              "      <td>VBG</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Labor</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>Party</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Sentence: 5</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1   Sentence: 1             of   IN      O\n",
              "2   Sentence: 1  demonstrators  NNS      O\n",
              "3   Sentence: 1           have  VBP      O\n",
              "4   Sentence: 1        marched  VBN      O\n",
              "..          ...            ...  ...    ...\n",
              "95  Sentence: 5             's  POS      O\n",
              "96  Sentence: 5         ruling  VBG      O\n",
              "97  Sentence: 5          Labor  NNP  B-org\n",
              "98  Sentence: 5          Party  NNP  I-org\n",
              "99  Sentence: 5             in   IN      O\n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_fEoMNCbPxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a class to get sentence. The each sentence will be list of tuples with its tag and pos.\n",
        "class sentence(object):\n",
        "    def __init__(self, df):\n",
        "        self.n_sent = 1\n",
        "        self.df = df\n",
        "        self.empty = False\n",
        "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
        "                                                       s['POS'].values.tolist(),\n",
        "                                                       s['Tag'].values.tolist())]\n",
        "        self.grouped = self.df.groupby(\"Sentence #\").apply(agg)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "        \n",
        "    def get_text(self):\n",
        "        try:\n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent +=1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIoy-HdrbTi2",
        "colab_type": "code",
        "outputId": "f683242f-4043-4d01-9763-ba8d926b69ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Displaying one full sentence\n",
        "getter = sentence(df)\n",
        "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
        "sentences[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS7KbuQpbY2Z",
        "colab_type": "code",
        "outputId": "6b2cf5e6-c332-46a3-e883-73c64414c741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#sentence with its pos and tag.\n",
        "sent = getter.get_text()\n",
        "print(sent)\n",
        "#getting all sentences\n",
        "sentences = getter.sentences\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSAdqfG7bhex",
        "colab_type": "text"
      },
      "source": [
        "## Feature Preparation\n",
        "These are the default features used by the NER in nltk. We can also modify it for our customization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBoMMBEybmkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5m2zBp3WgzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [sent2features(s) for s in sentences]\n",
        "y = [sent2labels(s) for s in sentences]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXFKbq57cgVl",
        "colab_type": "text"
      },
      "source": [
        "We must split the dataset to obtain training-test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL-sosyyWy41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VePnO1kvcJFs",
        "colab_type": "text"
      },
      "source": [
        "## CRF\n",
        "\n",
        "CRFs are used for predicting the sequences that use the contextual information to add information which will be used by the model to make a correct prediction.\n",
        "\n",
        "Below is the formula for CRF where y is the output variable and X is input sequence.\n",
        "\n",
        "\n",
        "\n",
        "<img src='https://d2ueix13hy5h3i.cloudfront.net/wp-content/uploads/2019/06/CodeCogsEqn1-6.png' width=500>\n",
        "\n",
        "https://www.aitimejournal.com/@akshay.chavan/introduction-to-conditional-random-fields-crfs\n",
        "\n",
        "The output sequence is modeled as the normalized product of the feature function.\n",
        "\n",
        "\n",
        "This process can take several minutes....\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDh-9H_Fbyvk",
        "colab_type": "code",
        "outputId": "ebb45da3-2ca2-4650-cc85-3731af82b2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "crf = CRF(algorithm = 'lbfgs',\n",
        "         c1 = 0.1,\n",
        "         c2 = 0.1,\n",
        "         max_iterations = 100,\n",
        "         all_possible_transitions = False)\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=False,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Da7CPWfb4n8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "9dddd18e-eac0-4ff1-e1c9-070da5a45302"
      },
      "source": [
        "#Predicting on the test set.\n",
        "y_pred = crf.predict(X_test)\n",
        "\n",
        "f1_score = flat_f1_score(y_test, y_pred, average = 'weighted')\n",
        "print(f1_score)\n",
        "\n",
        "report = flat_classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.971036183836736\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.56      0.14      0.23       104\n",
            "       B-eve       0.63      0.47      0.54        68\n",
            "       B-geo       0.85      0.91      0.88      7448\n",
            "       B-gpe       0.97      0.94      0.96      3179\n",
            "       B-nat       0.85      0.40      0.55        57\n",
            "       B-org       0.80      0.73      0.77      4020\n",
            "       B-per       0.85      0.83      0.84      3328\n",
            "       B-tim       0.92      0.88      0.90      4139\n",
            "       I-art       0.10      0.03      0.05        64\n",
            "       I-eve       0.43      0.38      0.41        52\n",
            "       I-geo       0.81      0.79      0.80      1487\n",
            "       I-gpe       0.97      0.62      0.76        50\n",
            "       I-nat       0.71      0.45      0.56        11\n",
            "       I-org       0.82      0.79      0.80      3331\n",
            "       I-per       0.86      0.89      0.87      3455\n",
            "       I-tim       0.85      0.75      0.79      1262\n",
            "           O       0.99      0.99      0.99    177356\n",
            "\n",
            "    accuracy                           0.97    209411\n",
            "   macro avg       0.76      0.65      0.69    209411\n",
            "weighted avg       0.97      0.97      0.97    209411\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}